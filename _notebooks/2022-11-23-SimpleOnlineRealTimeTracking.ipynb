{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5ae608-dbf1-43c2-b89a-e1a34885dbee",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This is an overview of the implementation details of SORT tracking algorithh. The official implemenation of the [paper](https://arxiv.org/abs/1602.00763) is present this [repo](https://github.com/abewley/sort) . The paper pretty much explains its straightforward ,  i will be more walking through the implemenation details. In a top level SORT is a tracking algorithm which falls in the class of tracking by detection and the detection, assoaciation , tracking cycle is happening in the 2D image domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38467655-6445-461c-94c2-45769d72b714",
   "metadata": {},
   "source": [
    "##  Detection\n",
    "\n",
    "Sort is a tracking by detection algorithm. So the quality of the tracking will inturn depends on the quality of detector. In the officiall implementation repo, the author have already porvided detections from the MOT Benchmark. So in the implementation present in the repo we can treat the detector as a blackbox and use the detection information already present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83944b1-d817-427d-a1aa-e9ef2e248795",
   "metadata": {},
   "source": [
    "### Motion Model and why we need it\n",
    "\n",
    "So we get detections in the current frame and we need to some how associate it to the detections from the previous frame. Seems  like  a place where we can put a Kalman filter into good use. So we use a kalman filter with constant velocity motion model and then we will treat the detections as measurements. The official implementation uses filterpy which is a python library with different kalman filter implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fcfd6-e8a9-4ca7-a6e1-d873a355547b",
   "metadata": {},
   "source": [
    "#### State Variables in the constant velocity model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a626bef-8d48-45e4-90cf-03ce6d2e2f72",
   "metadata": {},
   "source": [
    "So what are the state variables  \n",
    "u --> the horizontal pixel location of center of target  \n",
    "v --> the vertical pixel location of the center of target  \n",
    "s --> area (width_bbox*height_bbox)  \n",
    "r --> aspect ration (width_bbox/height_bbox)  \n",
    "\n",
    "We assume a constant velocity model and also assume the aspect ratio also remains constant, our process and measurement models will be based on that.  \n",
    "The state variables are [u,v,s,r,u_dot,v_dot,s_dot] where u_dot,v_dot and s_dot represent the corresponding velocities. Since we are assuming a constant velocity model we can use the normal newtons equations.  \n",
    "u = u + u_dot * t  \n",
    "v = v + v_dot * t  \n",
    "s = s + s_dot * t  \n",
    "r = r  \n",
    "u_dot = u_dot  \n",
    "v_dot = v_dot  \n",
    "s_dot = s_dot  \n",
    "\n",
    "The final process model will look like    \n",
    "x_(t+1) = F * x_(t) + ProcessNoise , For constant velocity model like above the process model will look something like shown below. As its shown from the output of the dot product, we get what we expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68961209-d83f-49c9-9aaa-e762d0bc3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols , Matrix\n",
    "u,v,s,r,u_dot,v_dot,s_dot = symbols('u,v,s,r,u_dot,v_dot,s_dot')\n",
    "F  = Matrix([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "x_ = Matrix([u,v,s,r,u_dot,v_dot,s_dot])\n",
    "out = F.dot(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56fb2d1c-66a3-4572-8b22-86fab9b8d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0 & 1 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 1 & 0\\\\0 & 0 & 1 & 0 & 0 & 0 & 1\\\\0 & 0 & 0 & 1 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 1 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 1 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 1\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 0, 0, 0, 1, 0, 0],\n",
       "[0, 1, 0, 0, 0, 1, 0],\n",
       "[0, 0, 1, 0, 0, 0, 1],\n",
       "[0, 0, 0, 1, 0, 0, 0],\n",
       "[0, 0, 0, 0, 1, 0, 0],\n",
       "[0, 0, 0, 0, 0, 1, 0],\n",
       "[0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3017e7b8-c353-48a2-a159-1384bfbc56c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u + u_dot, v + v_dot, s + s_dot, r, u_dot, v_dot, s_dot]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0eea6-aa7f-429e-ac4d-a2878dc38160",
   "metadata": {},
   "source": [
    "#### Measurement Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf0336-f895-45ae-b533-5c764dcad088",
   "metadata": {},
   "source": [
    "We use the variables u,v,s and r as measurements. We get these from the bounding box coordinates of each detections. So we need the measurement model to convert form the state space to the measurement space and the model is very simple 4x7 matrix with   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7ec1ac0-3274-4d26-8062-afa88178ca18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 1 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 1 & 0 & 0 & 0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 0, 0, 0, 0, 0, 0],\n",
       "[0, 1, 0, 0, 0, 0, 0],\n",
       "[0, 0, 1, 0, 0, 0, 0],\n",
       "[0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = Matrix([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a03d770b-37cc-4704-ae2b-3eaeaf4f931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u, v, s, r]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = H.dot(x_)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5d0e6-2de4-4121-9422-28332334bd5e",
   "metadata": {},
   "source": [
    "So thats about the kalman filter motion and measurement model and regarding the process noise since we are not observing velocties they are given high variances in the process matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924f479-6767-447d-9d4d-d02d3252bd89",
   "metadata": {},
   "source": [
    "## Core Sort Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f16c0e-305b-4a57-abdc-fff750b84fbb",
   "metadata": {},
   "source": [
    "``` python\n",
    "    #create instance of the SORT tracker , the min_hits are the minimum times the object needed to be redetected to be considered as a valid object\n",
    "    # max_age is the maximum age above which the object is ignored\n",
    "    mot_tracker = Sort(max_age=args.max_age, \n",
    "                       min_hits=args.min_hits,\n",
    "                       iou_threshold=args.iou_threshold) \n",
    "\n",
    "    \n",
    "      # we loop through each frame\n",
    "      for frame in range(int(seq_dets[:,0].max())):\n",
    "        frame += 1 #detection and frame numbers begin at 1\n",
    "        dets = seq_dets[seq_dets[:, 0]==frame, 2:7]\n",
    "        dets[:, 2:4] += dets[:, 0:2] #convert to [x1,y1,w,h] to [x1,y1,x2,y2]\n",
    "        total_frames += 1\n",
    "    \n",
    "        # this part is only needed if we are displaying\n",
    "        if(display):\n",
    "          fn = os.path.join('mot_benchmark', phase, seq, 'img1', '%06d.jpg'%(frame))\n",
    "          im =io.imread(fn)\n",
    "          ax1.imshow(im)\n",
    "          plt.title(seq + ' Tracked Targets')\n",
    "\n",
    "        start_time = time.time()\n",
    "        #The the tracker update, the kalman predict and update are done within this update method.\n",
    "        trackers = mot_tracker.update(dets)\n",
    "        cycle_time = time.time() - start_time\n",
    "        total_time += cycle_time\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2d29d-69c2-4c2a-8b39-892b23540777",
   "metadata": {},
   "source": [
    "Here we initially create an instance of the tracker and then loop through each frame and get the detections in those frames ,those detections are passed to the update method of the SORT. One point to note here is that within this update method the actual predict and update of the kalman is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4525b-cdb5-4ec8-8d85-1718b49a057b",
   "metadata": {},
   "source": [
    "### Update Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad70045-c99c-43e1-81a0-47bf13f0b507",
   "metadata": {},
   "source": [
    "1. For each unmatched detections an new kalmanfitler  will be created,and  in the very first loop all the kalman tracks will be created from the detections since we are not having any trackers to match against, but from the next frame onwards these trackers will be used to match against them. When a new kalman filter object is created for an unmatched detection  the kalmans state vector (the first four states which we get from measurement)  is with the intial measurement itself.\n",
    "2. If already initialized trackers are there the predict method for each of the existing trackers is called which is explained in detail below.  \n",
    "\n",
    "```python\n",
    " for t, trk in enumerate(trks):\n",
    "      pos = self.trackers[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "\n",
    "```\n",
    "\n",
    " \n",
    "  > *predict  method of Sort*\n",
    "  ```python\n",
    "\n",
    "    def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.age += 1\n",
    "    if(self.time_since_update>0):\n",
    "      self.hit_streak = 0\n",
    "    self.time_since_update += 1\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    return self.history[-1]\n",
    "      \n",
    "  ```\n",
    "  \n",
    "  \n",
    "  >  a.Initially we check for negative area and if so we set the rate of change of area as zero  \n",
    "  >  b.Then we do the kalman predict method which is F@x_state, and here the covariance also gets udpated.  \n",
    "  >  c.Then we increase the age of the tracker by one and check for time since the last update was called, if it was called in the last cycle we set the hit_streak to 0.   \n",
    "  >  d.Increase the time_since_update by 1. We set this back to zero in the update method of the kalman, this is means to know the if we had a valid kalman update for this tracker or not.  \n",
    "  >  e.We return the converted bounding box from measurement space x_center,y_center,scale,aspect ratio to x_top,y_top,x_bottom,y_bottom.\n",
    "  \n",
    "\n",
    "3. Now we associate the predicted trackers to detections.  \n",
    "    > *Associate predicted tracks to detections in the current frame*  \n",
    "    ```python\n",
    "        def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3): \n",
    "        \"\"\"\n",
    "        Assigns detections to tracked object (both represented as bounding boxes)\n",
    "\n",
    "        Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
    "        \"\"\"\n",
    "        # if the trackers is empty(happens in the begining of the cycle), we return all detections as unmatched\n",
    "        if(len(trackers)==0):\n",
    "            return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "\n",
    "        #here we find the iou between the detections and tracker\n",
    "        iou_matrix = iou_batch(detections, trackers)\n",
    "        \n",
    "        #the iou_matrix will be a one with shape detection_number x tracker_number\n",
    "        if min(iou_matrix.shape) > 0:\n",
    "            a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "        \n",
    "            #if all detection is only associated with only one tracker we can simply return where\n",
    "            if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "                matched_indices = np.stack(np.where(a), axis=1)\n",
    "            else:\n",
    "                #if more than one traker is associated with any detection we use the hungarian algo and find the indexes\n",
    "                matched_indices = linear_assignment(-iou_matrix)\n",
    "        else:\n",
    "            matched_indices = np.empty(shape=(0,2))\n",
    "\n",
    "        unmatched_detections = []\n",
    "        #here we loop through the detections and see if there any unmatched detections\n",
    "        for d, det in enumerate(detections):\n",
    "            if(d not in matched_indices[:,0]):\n",
    "                unmatched_detections.append(d)\n",
    "        unmatched_trackers = []\n",
    "        \n",
    "         #here we loop through the trackers  and see if there any unmatched detections\n",
    "        for t, trk in enumerate(trackers):\n",
    "            if(t not in matched_indices[:,1]):\n",
    "                unmatched_trackers.append(t)\n",
    "\n",
    "        #filter out matched with low IOU\n",
    "        matches = []\n",
    "        for m in matched_indices:\n",
    "            if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "                unmatched_detections.append(m[0])\n",
    "                unmatched_trackers.append(m[1])\n",
    "        else:\n",
    "            matches.append(m.reshape(1,2))\n",
    "        if(len(matches)==0):\n",
    "            matches = np.empty((0,2),dtype=int)\n",
    "        else:\n",
    "            matches = np.concatenate(matches,axis=0)\n",
    "\n",
    "        return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "    ```\n",
    "    > a. We first find the iou_matrix , this will have detections along the row and trackers along the column  \n",
    "    > b.Now if every row and column of the iou matrix only have one value above the iou_threshold then that row,col pair will be the match with with row for      detection id and col for tracked id.\n",
    "    > c.But if more than one mathces are there in every column then we do the linear_assignment using the hungarian alogrithm\n",
    "    > d.Then we check for the unmatched detection by seeing if there are any rows in the iou matches without the detection.\n",
    "    > e.Similarly we look for the unmatched tracks and see if there any column in the iou matches that are not there.\n",
    "    > f.Then we check for the iou_threshold and see and add to mathces and non matches accordingly , then finally return the matches((det,tracker) as (row,col)), unmatched_detection,unmatched_trackers\n",
    " \n",
    "\n",
    "\n",
    "4. Now update each of the tracker with the corresponding matched detections , the update method is explained in detail below.\n",
    "    > *update*\n",
    "    ```python\n",
    "       def update(self,bbox):\n",
    "            \"\"\"\n",
    "            Updates the state vector with observed bbox.\n",
    "            \"\"\"\n",
    "            self.time_since_update = 0\n",
    "            self.history = []\n",
    "            self.hits += 1\n",
    "            self.hit_streak += 1\n",
    "            self.kf.update(convert_bbox_to_z(bbox))\n",
    "\n",
    "    ```\n",
    "    > a.Initially we set the time since update to zero.    \n",
    "    > b.Then we set the history as an empty list  \n",
    "    > c.Then we increase the hits by 1  \n",
    "    > d. Then we call the kalman update but first have the change the bounding box form x_top,y_top,x_bottom,y_bottom to the x_center,y_center,scale,aspectRation   \n",
    "    \n",
    "\n",
    "5. Now we reverse the trackers and  get the state, then we check if time_since_update is < 1 , we set it to zero in the update part so here we are checking whether we have done update and only if we have done an update we append it to the output, also we check if the hit_streak(which also increase by one in the update method) is greater than the minimum hit streak unless its the begining frames.\n",
    "```python\n",
    "    i = len(self.trackers)\n",
    "    for trk in reversed(self.trackers):\n",
    "        d = trk.get_state()[0]\n",
    "        if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "             ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n",
    "        i -= 1\n",
    "        # remove dead tracklet\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "              self.trackers.pop(i)\n",
    "    if(len(ret)>0):\n",
    "          return np.concatenate(ret)\n",
    "    return np.empty((0,5))\n",
    "```\n",
    "\n",
    "6. We remove the dead trackers, meaning trackers that have not been assigned to any detections, by checking the time_since_update, the time_since_update is set to zero in the udpate method and is incremented in the predict method, so if we are only doing prediction without any update the time_since_update will increase and pass the maximum age and we will pop it from the trackers\n",
    "7. Finally we concatenate the detections and give them as out.\n",
    "8. Like this we keep updating looping through each frame and detection in it and the same detections should ideally have the same id until they disappear from the frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eccff3-1a20-44dd-ade9-6f90a588f6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
