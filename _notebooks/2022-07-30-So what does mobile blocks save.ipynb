{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79260d2-fe15-458c-bdbd-a48a71a809ef",
   "metadata": {},
   "source": [
    "# So How what does does mobile blocks save\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef191ccb-25a7-4334-b5a1-40d4ca4264a1",
   "metadata": {},
   "source": [
    "# Brief Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccb98e-bfdb-4082-aac1-928f6af6ddaa",
   "metadata": {},
   "source": [
    "This blog assumes the reader have a some understanding of mobileNet.This is just a lazy illustration of how much different mobileNet block save. The actual papers have the real numbers. If you want to know about the model please go through the papers [MobileNetV1](https://arxiv.org/abs/1704.04861) [MobileNetV2](https://arxiv.org/abs/1801.04381). In this we will briefly see how much parameters and floating point operations are required by a normal convolution block, mobileNetV1 and mobileNetV2 for the same input size. We will use torchinfo library for getting the summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f4c8e92-ccc9-4464-9b16-c6d9f079f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d948a98a-3a51-4cf9-a49a-c2640bdad2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the same input and outputs for all the conv blocks and mobile blocks\n",
    "input_filters = 64\n",
    "output_filters = 128\n",
    "input_size = (3,input_filters,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1df8e5e-522f-4619-abe7-17454a4b9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def printInputAndOutput(model,input_filters=64):\n",
    "    rand_tensor = torch.rand((3,input_filters,224,224))\n",
    "    out = model(rand_tensor)\n",
    "    print(\"Input shape = \", rand_tensor.shape)\n",
    "    print(\"Output shap =\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c9634-2847-41e0-a3df-82299cccb1fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Simple ConvNet Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d04ae94-38f3-485c-8628-bf2e4b8c51c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape =  torch.Size([3, 64, 224, 224])\n",
      "Output shap = torch.Size([3, 128, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "simple_convBlock = nn.Sequential(nn.Conv2d(in_channels=input_filters,out_channels=output_filters,kernel_size=3,stride=2,\n",
    "                                          padding=1,bias=False),nn.BatchNorm2d(output_filters),\n",
    "                                nn.ReLU(inplace=True))\n",
    "printInputAndOutput(simple_convBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7930b7-d5a0-4f41-924d-25bab2b97b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #                   Mult-Adds\n",
       "============================================================================================================================================\n",
       "Sequential                               --                        [3, 128, 112, 112]        --                        --\n",
       "├─Conv2d: 1-1                            [3, 3]                    [3, 128, 112, 112]        73,728                    2,774,532,096\n",
       "├─BatchNorm2d: 1-2                       --                        [3, 128, 112, 112]        256                       768\n",
       "├─ReLU: 1-3                              --                        [3, 128, 112, 112]        --                        --\n",
       "============================================================================================================================================\n",
       "Total params: 73,984\n",
       "Trainable params: 73,984\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.77\n",
       "============================================================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 77.07\n",
       "Params size (MB): 0.30\n",
       "Estimated Total Size (MB): 115.90\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(simple_convBlock,input_size=input_size,col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5655ac-a769-42a2-9f74-1ef5bba63610",
   "metadata": {},
   "source": [
    "# MobileNet Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b331d7-b588-44a3-85ff-7548b101bfdf",
   "metadata": {},
   "source": [
    "The main idea is to use depth wise convolution to reduce the parameters and floating point operations required. For more info please read the paper or watch this [tutorial](https://www.youtube.com/watch?v=GAbQYns1j2M) by Prof Maziar Raissi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4efae9ab-5def-4917-9b2b-0da143745263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape =  torch.Size([3, 64, 224, 224])\n",
      "Output shap = torch.Size([3, 128, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mobileNetBlock = nn.Sequential(\n",
    "                #DEPTHWISE CONV\n",
    "                #we get the depthwise convolution by specifying groups same as in_channels\n",
    "                nn.Conv2d(in_channels=input_filters,out_channels=input_filters,kernel_size=3,\n",
    "                         stride=2,padding=1,groups=input_filters,bias=False),\n",
    "                nn.BatchNorm2d(input_filters),\n",
    "                nn.ReLU(inplace=True),\n",
    "    \n",
    "                #POINTWISE CONV\n",
    "                nn.Conv2d(in_channels=input_filters,out_channels=output_filters,kernel_size=1,\n",
    "                          stride=1,padding=0,bias=False),\n",
    "                nn.BatchNorm2d(output_filters),\n",
    "                nn.ReLU(inplace=True)\n",
    "                )\n",
    "printInputAndOutput(mobileNetBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98613a17-e60b-4e0f-a85b-45fb43c40752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #                   Mult-Adds\n",
       "============================================================================================================================================\n",
       "Sequential                               --                        [3, 128, 112, 112]        --                        --\n",
       "├─Conv2d: 1-1                            [3, 3]                    [3, 64, 112, 112]         576                       21,676,032\n",
       "├─BatchNorm2d: 1-2                       --                        [3, 64, 112, 112]         128                       384\n",
       "├─ReLU: 1-3                              --                        [3, 64, 112, 112]         --                        --\n",
       "├─Conv2d: 1-4                            [1, 1]                    [3, 128, 112, 112]        8,192                     308,281,344\n",
       "├─BatchNorm2d: 1-5                       --                        [3, 128, 112, 112]        256                       768\n",
       "├─ReLU: 1-6                              --                        [3, 128, 112, 112]        --                        --\n",
       "============================================================================================================================================\n",
       "Total params: 9,152\n",
       "Trainable params: 9,152\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 329.96\n",
       "============================================================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 115.61\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 154.18\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mobileNetBlock,input_size=input_size,col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee51c3b-aaba-44ad-94db-76acca30d711",
   "metadata": {},
   "source": [
    "# MobileNetv2 Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0d866-cd48-4d1b-bf5c-3fa5291acfe2",
   "metadata": {},
   "source": [
    "The idea here is to add a residual connection and with this better perfomance was obtained with a slight increase in number of parameters. For more info please read the paper or watch this [tutorial](https://www.youtube.com/watch?v=hzj9kEU8QdA) by Prof Maziar Raissi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42d63059-ac42-4b50-a934-0eadb34e2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetv2Block(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels,expand_ratio,stride=1):\n",
    "        super(MobileNetv2Block,self).__init__()\n",
    "        self.conv1x1Begin = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,in_channels*expand_ratio,kernel_size=1,stride=1,bias=False),\n",
    "            nn.BatchNorm2d(in_channels*expand_ratio),\n",
    "            nn.ReLU6(inplace=True))\n",
    "        \n",
    "        self.convDepthWise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*expand_ratio,in_channels*expand_ratio,kernel_size=3,stride=stride,padding=1,groups=in_channels*expand_ratio,bias=False),\n",
    "            nn.BatchNorm2d(in_channels*expand_ratio),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.conv1x1Last = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*expand_ratio,out_channels,kernel_size=1,stride=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU6(inplace=True))\n",
    "        \n",
    "        self.stride = stride\n",
    "        \n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "        \n",
    "    def forward(self,x):\n",
    "        input_ = x     \n",
    "        x = self.conv1x1Begin(x)\n",
    "        x = self.convDepthWise(x)\n",
    "        x = self.conv1x1Last(x)\n",
    "\n",
    "        if self.use_res_connect:\n",
    "            return x+input_\n",
    "        else:\n",
    "            return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5af9b017-4eee-4131-ad77-521ac22076a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape =  torch.Size([3, 64, 224, 224])\n",
      "Output shap = torch.Size([3, 128, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "mobileNetV2Block = MobileNetv2Block(64,128,2,2)\n",
    "printInputAndOutput(mobileNetV2Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bf2744c-8701-43bb-8190-7da8a00e7dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #                   Mult-Adds\n",
       "============================================================================================================================================\n",
       "MobileNetv2Block                         --                        [3, 128, 112, 112]        --                        --\n",
       "├─Sequential: 1-1                        --                        [3, 128, 224, 224]        --                        --\n",
       "│    └─Conv2d: 2-1                       [1, 1]                    [3, 128, 224, 224]        8,192                     1,233,125,376\n",
       "│    └─BatchNorm2d: 2-2                  --                        [3, 128, 224, 224]        256                       768\n",
       "│    └─ReLU6: 2-3                        --                        [3, 128, 224, 224]        --                        --\n",
       "├─Sequential: 1-2                        --                        [3, 128, 112, 112]        --                        --\n",
       "│    └─Conv2d: 2-4                       [3, 3]                    [3, 128, 112, 112]        1,152                     43,352,064\n",
       "│    └─BatchNorm2d: 2-5                  --                        [3, 128, 112, 112]        256                       768\n",
       "│    └─ReLU6: 2-6                        --                        [3, 128, 112, 112]        --                        --\n",
       "├─Sequential: 1-3                        --                        [3, 128, 112, 112]        --                        --\n",
       "│    └─Conv2d: 2-7                       [1, 1]                    [3, 128, 112, 112]        16,384                    616,562,688\n",
       "│    └─BatchNorm2d: 2-8                  --                        [3, 128, 112, 112]        256                       768\n",
       "│    └─ReLU6: 2-9                        --                        [3, 128, 112, 112]        --                        --\n",
       "============================================================================================================================================\n",
       "Total params: 26,496\n",
       "Trainable params: 26,496\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.89\n",
       "============================================================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 462.42\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 501.06\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mobileNetV2Block,input_size=input_size,col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76fbb7-3789-4c0b-9074-2456be6c5954",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462d0cf-1f9e-4064-8e88-fe8660615403",
   "metadata": {},
   "source": [
    "Now we can compare the summaries of each block. From the above cells we can observe that the inputs and output shapes remains the same\n",
    "\n",
    "#### 1)SimpleConvBlock\n",
    "\n",
    "`Total params: 73,984`\n",
    "\n",
    "`Trainable params: 73,984`\n",
    "\n",
    "`Non-trainable params: 0`\n",
    "\n",
    "`Total mult-adds (G): 2.77`\n",
    "\n",
    "#### 2)MobileNetV1\n",
    "\n",
    "`Total params: 9,152`\n",
    "\n",
    "`Trainable params: 9,152`\n",
    "\n",
    "`Non-trainable params: 0`\n",
    "\n",
    "`Total mult-adds (M): 329.96`\n",
    "\n",
    "#### 3)MobileNetV2\n",
    "\n",
    "`Total params: 26,496`\n",
    "\n",
    "`Trainable params: 26,496`\n",
    "\n",
    "`Non-trainable params: 0`\n",
    "\n",
    "`Total mult-adds (G): 1.89`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696a345-961d-4c1c-b459-f2329b4b4a6e",
   "metadata": {},
   "source": [
    "If you look at the outputs of torchinfo you can see that the estimated total size is more for mobileNets than simpleConv block this isbecause we need to store 2 times the intermediate values during training  , but this wont be a problem for inference, during inference we only need to store the parameters and architecture, and thus looking above we can see that way fever parameters and total number of multiplications and additions needed is also low which helps in faster inference. If you want more info please read the papers which are well written. If you want to read about how the torchinfo works please read this [blog](http://jck.bio/pytorch_estimating_model_size/) by Jacob C. Kimmel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2506e-a4ee-427b-b9a6-752b0b71d349",
   "metadata": {},
   "source": [
    "# Doing all the above with torchvision classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbb88b-afb8-4e10-b4e3-006fb6723bdf",
   "metadata": {},
   "source": [
    "Actually all the above was taken from torchvision only we can do the same easily with torchvision classes as show below and all credits are to the amazing torchvision library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8a3e30-dd60-4512-bb82-6457f92fae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.mobilenetv2 import MobileNetV2, InvertedResidual,ConvNormActivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3425507-caba-4649-b29e-6984b81f1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to put the expand_ratio as one which will reduce this to a simple mobilenetV1 block\n",
    "TorchMobileNetV1Block = InvertedResidual(64,128,stride=2,expand_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "889ff676-06be-425f-b127-6a7e211b83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TorchMobileNetV2Block = InvertedResidual(64,128,stride=2,expand_ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed3c310-502e-44f8-8cf3-d4f361bd4370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape =  torch.Size([3, 64, 224, 224])\n",
      "Output shap = torch.Size([3, 128, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "printInputAndOutput(TorchMobileNetV1Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b389f05-06a7-4868-a3c6-e6326e473328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape =  torch.Size([3, 64, 224, 224])\n",
      "Output shap = torch.Size([3, 128, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "printInputAndOutput(TorchMobileNetV2Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d151c6c1-3ec7-4e69-966c-8b25885ec6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #                   Mult-Adds\n",
       "============================================================================================================================================\n",
       "InvertedResidual                         --                        [3, 128, 112, 112]        --                        --\n",
       "├─Sequential: 1-1                        --                        [3, 128, 112, 112]        --                        --\n",
       "│    └─ConvNormActivation: 2-1           --                        [3, 64, 112, 112]         --                        --\n",
       "│    │    └─Conv2d: 3-1                  [3, 3]                    [3, 64, 112, 112]         576                       21,676,032\n",
       "│    │    └─BatchNorm2d: 3-2             --                        [3, 64, 112, 112]         128                       384\n",
       "│    │    └─ReLU6: 3-3                   --                        [3, 64, 112, 112]         --                        --\n",
       "│    └─Conv2d: 2-2                       [1, 1]                    [3, 128, 112, 112]        8,192                     308,281,344\n",
       "│    └─BatchNorm2d: 2-3                  --                        [3, 128, 112, 112]        256                       768\n",
       "============================================================================================================================================\n",
       "Total params: 9,152\n",
       "Trainable params: 9,152\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 329.96\n",
       "============================================================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 115.61\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 154.18\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(TorchMobileNetV1Block,input_size=input_size,col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ed2882b-0fa5-4172-af63-5cdca71083db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #                   Mult-Adds\n",
       "============================================================================================================================================\n",
       "InvertedResidual                         --                        [3, 128, 112, 112]        --                        --\n",
       "├─Sequential: 1-1                        --                        [3, 128, 112, 112]        --                        --\n",
       "│    └─ConvNormActivation: 2-1           --                        [3, 128, 224, 224]        --                        --\n",
       "│    │    └─Conv2d: 3-1                  [1, 1]                    [3, 128, 224, 224]        8,192                     1,233,125,376\n",
       "│    │    └─BatchNorm2d: 3-2             --                        [3, 128, 224, 224]        256                       768\n",
       "│    │    └─ReLU6: 3-3                   --                        [3, 128, 224, 224]        --                        --\n",
       "│    └─ConvNormActivation: 2-2           --                        [3, 128, 112, 112]        --                        --\n",
       "│    │    └─Conv2d: 3-4                  [3, 3]                    [3, 128, 112, 112]        1,152                     43,352,064\n",
       "│    │    └─BatchNorm2d: 3-5             --                        [3, 128, 112, 112]        256                       768\n",
       "│    │    └─ReLU6: 3-6                   --                        [3, 128, 112, 112]        --                        --\n",
       "│    └─Conv2d: 2-3                       [1, 1]                    [3, 128, 112, 112]        16,384                    616,562,688\n",
       "│    └─BatchNorm2d: 2-4                  --                        [3, 128, 112, 112]        256                       768\n",
       "============================================================================================================================================\n",
       "Total params: 26,496\n",
       "Trainable params: 26,496\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.89\n",
       "============================================================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 462.42\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 501.06\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(TorchMobileNetV2Block,input_size=input_size,col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
