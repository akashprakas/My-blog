{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the losses in CenterNet Architecture\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is  a small demo of the how the ground truths and loss will look in centerNet. Most of the code is from [MMdetection](https://github.com/open-mmlab/mmdetection). The idea here is to show a demo part so that the code is understandable. My repo for understanding the architecure can be found [here](https://github.com/akashprakas/CenterNet) . To understand the architecture please go through the blog by [Shreejal Trivedi](https://medium.com/visionwizard/centernet-objects-as-points-a-comprehensive-guide-2ed9993c48bc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to generate the groundTruth heat maps\n",
    "\n",
    "1. We need to generate heatmap, the heatmap is generated such that at the center of the image, where the bounding box is  the value will be 1 and decreasing around it like a gaussian.\n",
    "2. To calculate the radius we use the bbox height and width which have been scaled down to the feature map level.\n",
    "3. We can use the same function used in [MMdetection](https://mmdetection.readthedocs.io/en/latest/_modules/mmdet/models/utils/gaussian_target.html). You can find the detailed description in this [link](https://mmdetection.readthedocs.io/en/latest/_modules/mmdet/models/utils/gaussian_target.html)\n",
    "5. Lets assume that our initial image was of size (64,64) and it was scaled down to (8,8) after the feature maps and lets assume the radius is 2, in reality the radius is calculated as the function shown below based on the bounding box size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def gaussian2D(radius, sigma=1, dtype=torch.float32, device='cpu'):\n",
    "    \"\"\"Generate 2D gaussian kernel.\n",
    "\n",
    "    Args:\n",
    "        radius (int): Radius of gaussian kernel.\n",
    "        sigma (int): Sigma of gaussian function. Default: 1.\n",
    "        dtype (torch.dtype): Dtype of gaussian tensor. Default: torch.float32.\n",
    "        device (str): Device of gaussian tensor. Default: 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        h (Tensor): Gaussian kernel with a\n",
    "            ``(2 * radius + 1) * (2 * radius + 1)`` shape.\n",
    "    \"\"\"\n",
    "    x = torch.arange(\n",
    "        -radius, radius + 1, dtype=dtype, device=device).view(1, -1)\n",
    "    y = torch.arange(\n",
    "        -radius, radius + 1, dtype=dtype, device=device).view(-1, 1)\n",
    "\n",
    "    h = (-(x * x + y * y) / (2 * sigma * sigma)).exp()\n",
    "\n",
    "    h[h < torch.finfo(h.dtype).eps * h.max()] = 0\n",
    "    return h\n",
    "\n",
    "\n",
    "def gen_gaussian_target(heatmap, center, radius, k=1):\n",
    "    \"\"\"Generate 2D gaussian heatmap.\n",
    "\n",
    "    Args:\n",
    "        heatmap (Tensor): Input heatmap, the gaussian kernel will cover on\n",
    "            it and maintain the max value.\n",
    "        center (list[int]): Coord of gaussian kernel's center.\n",
    "        radius (int): Radius of gaussian kernel.\n",
    "        k (int): Coefficient of gaussian kernel. Default: 1.\n",
    "\n",
    "    Returns:\n",
    "        out_heatmap (Tensor): Updated heatmap covered by gaussian kernel.\n",
    "    \"\"\"\n",
    "    diameter = 2 * radius + 1\n",
    "    gaussian_kernel = gaussian2D(\n",
    "        radius, sigma=diameter / 6, dtype=heatmap.dtype, device=heatmap.device)\n",
    "\n",
    "    x, y = center\n",
    "\n",
    "    height, width = heatmap.shape[:2]\n",
    "\n",
    "    left, right = min(x, radius), min(width - x, radius + 1)\n",
    "    top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "    masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "    masked_gaussian = gaussian_kernel[radius - top:radius + bottom,\n",
    "                                      radius - left:radius + right]\n",
    "    out_heatmap = heatmap\n",
    "    torch.max(\n",
    "        masked_heatmap,\n",
    "        masked_gaussian * k,\n",
    "        out=out_heatmap[y - top:y + bottom, x - left:x + right])\n",
    "\n",
    "    return out_heatmap\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_radius(det_size, min_overlap):\n",
    "    r\"\"\"Generate 2D gaussian radius.\n",
    "\n",
    "    This function is modified from the `official github repo\n",
    "    <https://github.com/princeton-vl/CornerNet-Lite/blob/master/core/sample/\n",
    "    utils.py#L65>`_.\n",
    "\n",
    "    Given ``min_overlap``, radius could computed by a quadratic equation\n",
    "    according to Vieta's formulas.\n",
    "\n",
    "    There are 3 cases for computing gaussian radius, details are following:\n",
    "\n",
    "    - Explanation of figure: ``lt`` and ``br`` indicates the left-top and\n",
    "      bottom-right corner of ground truth box. ``x`` indicates the\n",
    "      generated corner at the limited position when ``radius=r``.\n",
    "\n",
    "    - Case1: one corner is inside the gt box and the other is outside.\n",
    "\n",
    "    .. code:: text\n",
    "\n",
    "        |<   width   >|\n",
    "\n",
    "        lt-+----------+         -\n",
    "        |  |          |         ^\n",
    "        +--x----------+--+\n",
    "        |  |          |  |\n",
    "        |  |          |  |    height\n",
    "        |  | overlap  |  |\n",
    "        |  |          |  |\n",
    "        |  |          |  |      v\n",
    "        +--+---------br--+      -\n",
    "           |          |  |\n",
    "           +----------+--x\n",
    "\n",
    "    To ensure IoU of generated box and gt box is larger than ``min_overlap``:\n",
    "\n",
    "    .. math::\n",
    "        \\cfrac{(w-r)*(h-r)}{w*h+(w+h)r-r^2} \\ge {iou} \\quad\\Rightarrow\\quad\n",
    "        {r^2-(w+h)r+\\cfrac{1-iou}{1+iou}*w*h} \\ge 0 \\\\\n",
    "        {a} = 1,\\quad{b} = {-(w+h)},\\quad{c} = {\\cfrac{1-iou}{1+iou}*w*h}\n",
    "        {r} \\le \\cfrac{-b-\\sqrt{b^2-4*a*c}}{2*a}\n",
    "\n",
    "    - Case2: both two corners are inside the gt box.\n",
    "\n",
    "    .. code:: text\n",
    "\n",
    "        |<   width   >|\n",
    "\n",
    "        lt-+----------+         -\n",
    "        |  |          |         ^\n",
    "        +--x-------+  |\n",
    "        |  |       |  |\n",
    "        |  |overlap|  |       height\n",
    "        |  |       |  |\n",
    "        |  +-------x--+\n",
    "        |          |  |         v\n",
    "        +----------+-br         -\n",
    "\n",
    "    To ensure IoU of generated box and gt box is larger than ``min_overlap``:\n",
    "\n",
    "    .. math::\n",
    "        \\cfrac{(w-2*r)*(h-2*r)}{w*h} \\ge {iou} \\quad\\Rightarrow\\quad\n",
    "        {4r^2-2(w+h)r+(1-iou)*w*h} \\ge 0 \\\\\n",
    "        {a} = 4,\\quad {b} = {-2(w+h)},\\quad {c} = {(1-iou)*w*h}\n",
    "        {r} \\le \\cfrac{-b-\\sqrt{b^2-4*a*c}}{2*a}\n",
    "\n",
    "    - Case3: both two corners are outside the gt box.\n",
    "\n",
    "    .. code:: text\n",
    "\n",
    "           |<   width   >|\n",
    "\n",
    "        x--+----------------+\n",
    "        |  |                |\n",
    "        +-lt-------------+  |   -\n",
    "        |  |             |  |   ^\n",
    "        |  |             |  |\n",
    "        |  |   overlap   |  | height\n",
    "        |  |             |  |\n",
    "        |  |             |  |   v\n",
    "        |  +------------br--+   -\n",
    "        |                |  |\n",
    "        +----------------+--x\n",
    "\n",
    "    To ensure IoU of generated box and gt box is larger than ``min_overlap``:\n",
    "\n",
    "    .. math::\n",
    "        \\cfrac{w*h}{(w+2*r)*(h+2*r)} \\ge {iou} \\quad\\Rightarrow\\quad\n",
    "        {4*iou*r^2+2*iou*(w+h)r+(iou-1)*w*h} \\le 0 \\\\\n",
    "        {a} = {4*iou},\\quad {b} = {2*iou*(w+h)},\\quad {c} = {(iou-1)*w*h} \\\\\n",
    "        {r} \\le \\cfrac{-b+\\sqrt{b^2-4*a*c}}{2*a}\n",
    "\n",
    "    Args:\n",
    "        det_size (list[int]): Shape of object.\n",
    "        min_overlap (float): Min IoU with ground truth for boxes generated by\n",
    "            keypoints inside the gaussian kernel.\n",
    "\n",
    "    Returns:\n",
    "        radius (int): Radius of gaussian kernel.\n",
    "    \"\"\"\n",
    "    height, width = det_size\n",
    "\n",
    "    a1 = 1\n",
    "    b1 = (height + width)\n",
    "    c1 = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = sqrt(b1**2 - 4 * a1 * c1)\n",
    "    r1 = (b1 - sq1) / (2 * a1)\n",
    "\n",
    "    a2 = 4\n",
    "    b2 = 2 * (height + width)\n",
    "    c2 = (1 - min_overlap) * width * height\n",
    "    sq2 = sqrt(b2**2 - 4 * a2 * c2)\n",
    "    r2 = (b2 - sq2) / (2 * a2)\n",
    "\n",
    "    a3 = 4 * min_overlap\n",
    "    b3 = -2 * min_overlap * (height + width)\n",
    "    c3 = (min_overlap - 1) * width * height\n",
    "    sq3 = sqrt(b3**2 - 4 * a3 * c3)\n",
    "    r3 = (b3 + sq3) / (2 * a3)\n",
    "    return min(r1, r2, r3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = gaussian2D(radius=2, sigma=1, dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0183, 0.0821, 0.1353, 0.0821, 0.0183],\n",
       "        [0.0821, 0.3679, 0.6065, 0.3679, 0.0821],\n",
       "        [0.1353, 0.6065, 1.0000, 0.6065, 0.1353],\n",
       "        [0.0821, 0.3679, 0.6065, 0.3679, 0.0821],\n",
       "        [0.0183, 0.0821, 0.1353, 0.0821, 0.0183]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our radius was 2 so we can see that at (2,2) the magnitude is 1 and in a gaussian kernel way,it decreases around.Now this heatmap will be copied to the center as required, but if the center is at the corners then cropping of the heatmap might be requried as needed\n",
    "1. As in the begining assume that the heatmap is of shape 8,8 and lets assume that the object is located at the center (3,3). \n",
    "2. So we need to copy the ground truth heatMap to that position as is as shown in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 2\n",
    "heatmap = torch.zeros((8,8))\n",
    "height, width = heatmap.shape[:2]\n",
    "center=(3,3)\n",
    "x, y = center\n",
    "# we are doing this because the kernel may lie outside the heatmap for example near corners\n",
    "left, right = min(x, radius), min(width - x, radius + 1)\n",
    "top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "masked_gaussian = h[radius - top:radius + bottom,\n",
    "                                      radius - left:radius + right]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0183, 0.0821, 0.1353, 0.0821, 0.0183],\n",
       "        [0.0821, 0.3679, 0.6065, 0.3679, 0.0821],\n",
       "        [0.1353, 0.6065, 1.0000, 0.6065, 0.1353],\n",
       "        [0.0821, 0.3679, 0.6065, 0.3679, 0.0821],\n",
       "        [0.0183, 0.0821, 0.1353, 0.0821, 0.0183]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0183, 0.0821, 0.1353, 0.0821, 0.0183],\n",
       "        [0.0821, 0.3679, 0.6065, 0.3679, 0.0821],\n",
       "        [0.1353, 0.6065, 1.0000, 0.6065, 0.1353],\n",
       "        [0.0821, 0.3679, 0.6065, 0.3679, 0.0821],\n",
       "        [0.0183, 0.0821, 0.1353, 0.0821, 0.0183]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_heatmap = heatmap\n",
    "torch.max(\n",
    "        masked_heatmap,\n",
    "        masked_gaussian ,\n",
    "        out=out_heatmap[y - top:y + bottom, x - left:x + right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0183, 0.0821, 0.1353, 0.0821, 0.0183, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0821, 0.3679, 0.6065, 0.3679, 0.0821, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1353, 0.6065, 1.0000, 0.6065, 0.1353, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0821, 0.3679, 0.6065, 0.3679, 0.0821, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0183, 0.0821, 0.1353, 0.0821, 0.0183, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_heatmap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the heatmap has been placed with a value of 1 as (3,3) which is the center we gave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at how the losses will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HeatMap loss\n",
    "\n",
    "1. Suppose we have 4 classes, 2 batches and feature map size be 8, then the predicted heatmap will be of shape 2,4,8,8 . (batch,num_classes,height,width)\n",
    "2. Suppose we have two images and  one bounding box each in two images, let the first image have class id 0 and the second image have classid 2 . So the corresponding depth will have the heatmap gaussian as the ground truth with center having one and the gaussian kernel spread around.\n",
    "3. For now we will use the above geneareted heatmap as the  object , that is we have object at center 3,3 at id 0 in first image and at id 2 in second image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth shape torch.Size([2, 4, 8, 8])\n",
      "Ground Truth \n",
      " tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0183, 0.0821, 0.1353, 0.0821, 0.0183, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0821, 0.3679, 0.6065, 0.3679, 0.0821, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1353, 0.6065, 1.0000, 0.6065, 0.1353, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0821, 0.3679, 0.6065, 0.3679, 0.0821, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0183, 0.0821, 0.1353, 0.0821, 0.0183, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0183, 0.0821, 0.1353, 0.0821, 0.0183, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0821, 0.3679, 0.6065, 0.3679, 0.0821, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1353, 0.6065, 1.0000, 0.6065, 0.1353, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0821, 0.3679, 0.6065, 0.3679, 0.0821, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0183, 0.0821, 0.1353, 0.0821, 0.0183, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "groundTruth = torch.zeros((2,4,8,8),dtype=torch.float32)\n",
    "print(\"GroundTruth shape\",groundTruth.shape)\n",
    "# now we need to copy the heat map we generated above to the positions of the class ids,\n",
    "# here we have assumed the in the first image the class id 0 is having the bounding box\n",
    "# and in the image 2 the classid 2 is having the object, for simplicity we are assuming\n",
    "# that both the images have same heat map an center, the assignment is as follows then\n",
    "groundTruth[0,0,:,:] = out_heatmap.clone()\n",
    "groundTruth[1,2,:,:] = out_heatmap.clone()\n",
    "print(\"Ground Truth \\n\",groundTruth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make a random prediction and see how we calculate the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.randn(2,4,8,8,dtype=torch.float32).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss is as the described in the paper and is a modified focal loss\n",
    "alpha = 2.0\n",
    "gamma = 4.0\n",
    "eps = 1e-12\n",
    "pos_weights = groundTruth.eq(1)\n",
    "neg_weigths = (1 - groundTruth).pow(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heat map we can see that the negative samples will be much more and therefore they introduced this modified version of focal loss to counteract that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(181.3507)\n"
     ]
    }
   ],
   "source": [
    "pos_loss = -(pred+eps).log()*(1 - pred).pow(alpha)*pos_weights\n",
    "neg_loss = -(1 - pred+ eps).log()*pred.pow(alpha)*neg_weigths\n",
    "final_loss = pos_loss + neg_loss\n",
    "print(final_loss.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroundTruth WH and WH offset\n",
    "\n",
    "1. The the head predicts the wh in the shape of batch,2,height,widht and the same is the shape of offset head\n",
    "2. For wh head the bbox scaled down widht and height will be placed at the indexes 0 and 1.\n",
    "3. For offset head the the corressponding difference in offset will be placed at the corresponding indexes.\n",
    "4. To understand it better, initially we have assumed that we have an image of shape (64,64) and after scaling down it becomes (8,8). And suppose in the original image the bounding box center is at (28,28) so when we scale it down to feature map level it becomem 28/8 = 3.5 and we have to take the int of that so the offset difference is (3.5 -3) which is 0.5. Its as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal scaled down  (3.5, 3.5)\n",
      "floored version  (3, 3)\n",
      "offset is  (0.5, 0.5)\n"
     ]
    }
   ],
   "source": [
    "#so cx and cy will be \n",
    "ctx,cty = 28/8 ,28/8\n",
    "ctx_int,cty_int = int(ctx),int(cty)\n",
    "\n",
    "print(\"orginal scaled down \",(ctx, cty) )\n",
    "print(\"floored version \" ,(ctx_int,cty_int))\n",
    "print(\"offset is \",(ctx- ctx_int,cty-cty_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we generate the ground truth\n",
    "groundTruthWH =torch.zeros((2,2,8,8),dtype=torch.float32)\n",
    "groundTruthWHOffset = torch.zeros((2,2,8,8),dtype=torch.float32)\n",
    "groundTruthWHOffsetWeights = torch.zeros((2,2,8,8),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so for the we have said that the object is same position in both the images, so when\n",
    "# groundTruth is set the to be predicted width and height at the same position\n",
    "\n",
    "groundTruthWHOffset[0,0,ctx_int,cty_int] = ctx- ctx_int\n",
    "groundTruthWHOffset[0,1,ctx_int,cty_int] = cty-cty_int\n",
    "\n",
    "\n",
    "# we are asuming the object is at the same position in both the images so the\n",
    "# above will be the same for batchid 1\n",
    "groundTruthWHOffset[1,0,ctx_int,cty_int] = ctx- ctx_int\n",
    "groundTruthWHOffset[1,1,ctx_int,cty_int] = cty-cty_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need set weights because we need to consider loss only from the places\n",
    "there was an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruthWHOffsetWeights[0,:,ctx_int,cty_int] = 1\n",
    "#since the second batch image is also at the same place\n",
    "groundTruthWHOffsetWeights[1,:,ctx_int,cty_int] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a random prediction to calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predWH = torch.randn((2,2,8,8),dtype=torch.float32)\n",
    "predWHOffset = torch.randn((2,2,8,8),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss we use for the wh and wh_offset are the same and is the l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(pred, target):\n",
    "    \"\"\"L1 loss.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): The prediction.\n",
    "        target (torch.Tensor): The learning target of the prediction.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Calculated loss\n",
    "    \"\"\"\n",
    "    if target.numel() == 0:\n",
    "        return pred.sum() * 0\n",
    "\n",
    "    assert pred.size() == target.size()\n",
    "    loss = torch.abs(pred - target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note we are multiplying by the weights in the end to get the loss from required poistion only\n",
    "WHLoss = l1_loss(predWH,groundTruthWH)*groundTruthWHOffsetWeights\n",
    "WHOffsetLoss = l1_loss(predWHOffset,groundTruthWHOffset)*groundTruthWHOffsetWeights\n",
    "\n",
    "WHLoss = WHLoss.sum()\n",
    "WHOffsetLoss = WHOffsetLoss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Loss  tensor(3.6995)\n",
      "Ground Offset Loss  tensor(2.0938)\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground Truth Loss \",WHLoss)\n",
    "print(\"Ground Offset Loss \",WHOffsetLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final loss is the weighted sum of the heapmap loss, wh loss and wh_offset loss.There is a little more things involved and in the [repo](https://github.com/akashprakas/CenterNet) i have showed how these are actually done in a real implemenation. Hope this was helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e42c82c2f9660bed9998ad53df6d834ef390915492fb6673fd3a6923ddeb34a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
